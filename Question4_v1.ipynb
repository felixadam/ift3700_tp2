{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faut ajouter le fichier \"adult.csv\" qui n'est pas inclut dans notre remise\n",
    "def load_original():\n",
    "    return pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# Voir `preprocess(df)` plus bas\n",
    "def load_modified():\n",
    "    return pd.read_csv(\"adult-modified.csv\")\n",
    "\n",
    "#df = load_original()\n",
    "df = load_modified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22379</td>\n",
       "      <td>6172</td>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43832</td>\n",
       "      <td>37155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.165268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.939211e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5711.725564</td>\n",
       "      <td>295.394230</td>\n",
       "      <td>43.844642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.060112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.125794e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7227.660657</td>\n",
       "      <td>361.260868</td>\n",
       "      <td>12.818377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.452000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.500000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.452000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.500000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.235600e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.500000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.235600e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.500000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.564920e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104989.500000</td>\n",
       "      <td>4567.500000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass        fnlwgt education  educational-num  \\\n",
       "count   48842.000000     48842  4.884200e+04     48842     48842.000000   \n",
       "unique           NaN         9           NaN        16              NaN   \n",
       "top              NaN   Private           NaN   HS-grad              NaN   \n",
       "freq             NaN     33906           NaN     15784              NaN   \n",
       "mean       39.165268       NaN  1.939211e+05       NaN        10.078089   \n",
       "std        14.060112       NaN  1.125794e+05       NaN         2.570973   \n",
       "min        15.000000       NaN  7.452000e+04       NaN         1.000000   \n",
       "25%        25.000000       NaN  7.452000e+04       NaN         9.000000   \n",
       "50%        35.000000       NaN  2.235600e+05       NaN        10.000000   \n",
       "75%        45.000000       NaN  2.235600e+05       NaN        12.000000   \n",
       "max        95.000000       NaN  1.564920e+06       NaN        16.000000   \n",
       "\n",
       "            marital-status      occupation relationship   race gender  \\\n",
       "count                48842           48842        48842  48842  48842   \n",
       "unique                   7              15            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                 22379            6172        19716  41762  32650   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "         capital-gain  capital-loss  hours-per-week native-country income  \n",
       "count    48842.000000  48842.000000    48842.000000          48842  48842  \n",
       "unique            NaN           NaN             NaN             42      2  \n",
       "top               NaN           NaN             NaN  United-States  <=50K  \n",
       "freq              NaN           NaN             NaN          43832  37155  \n",
       "mean      5711.725564    295.394230       43.844642            NaN    NaN  \n",
       "std       7227.660657    361.260868       12.818377            NaN    NaN  \n",
       "min       4999.500000    217.500000        5.000000            NaN    NaN  \n",
       "25%       4999.500000    217.500000       45.000000            NaN    NaN  \n",
       "50%       4999.500000    217.500000       45.000000            NaN    NaN  \n",
       "75%       4999.500000    217.500000       45.000000            NaN    NaN  \n",
       "max     104989.500000   4567.500000       95.000000            NaN    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-priori\n",
    "A-priori sera utilisé ici pour trouver les patrons les plus fréquents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Je veux ici réduire le nombre de valeur possible\n",
    "    # Parce que des patrons différents pour 50 ans et 51 ans ne\n",
    "    # devrait pas vraiment être différents\n",
    "    for age in df['age'].unique():\n",
    "        df.loc[df['age'] == age, 'age'] = ((age // 10) * 10 + 5)\n",
    "    \n",
    "    gain_step = df['capital-gain'].max() // 10\n",
    "    loss_step = df['capital-loss'].max() // 10\n",
    "    \n",
    "    for gain in df['capital-gain'].unique():\n",
    "        df.loc[df['capital-gain'] == gain, 'capital-gain'] = ((gain // gain_step) * gain_step + (gain_step / 2))\n",
    "    \n",
    "    for loss in df['capital-loss'].unique():\n",
    "        df.loc[df['capital-loss'] == loss, 'capital-loss'] = ((loss // loss_step) * loss_step + (loss_step / 2))\n",
    "    \n",
    "    fnlwgt_step = df['fnlwgt'].max() // 10\n",
    "    \n",
    "    for w in df['fnlwgt'].unique():\n",
    "        df.loc[df['fnlwgt'] == w, 'fnlwgt'] = ((w // fnlwgt_step) * fnlwgt_step + (fnlwgt_step / 2))\n",
    "    \n",
    "    for h in df['hours-per-week'].unique():\n",
    "        df.loc[df['hours-per-week'] == h, 'hours-per-week'] = ((h // 10) * 10 + 5)\n",
    "    \n",
    "    df.to_csv('adult-modified.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`patterns` va ici contenir les éléments les plus fréquents pour chaque colonne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent(data, count):\n",
    "    patterns = dict()\n",
    "    for c in data: # iterate over columns\n",
    "        # get the most frequent values\n",
    "        # `value_counts` sort in descending order\n",
    "        patterns[c] = data[c].value_counts()\n",
    "        for r in patterns[c]: # iterate over rows\n",
    "            if len(patterns[c]) >= count:\n",
    "                patterns[c] = patterns[c].iloc[:count]\n",
    "    #print(patterns)\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_impl(data, num_key, max_id_key, pattern_min, done_index):\n",
    "    if num_key <= 0:\n",
    "        # Retourne un type différent de `result` !!!\n",
    "        return data.describe(include='all') #return data # A leaf\n",
    "    patterns = get_most_frequent(data, max_id_key)\n",
    "    result = dict()\n",
    "    for key in patterns.keys():\n",
    "        if (key not in done_index):\n",
    "            done_index |= set([key])\n",
    "            for idx in range(len(patterns[key].index)):\n",
    "                value = patterns[key].index[idx]\n",
    "                #print(key + \":\" + str(value))\n",
    "                data_c = data[data[key] == patterns[key].index[idx]]\n",
    "                #print(data_c.shape)\n",
    "                if (data_c.shape[0] >= pattern_min):\n",
    "                    result[(key, value)] = apriori_impl(data_c,num_key - 1,max_id_key,pattern_min,done_index)\n",
    "    return result\n",
    "\n",
    "def apriori(data, num_key, max_id_key, pattern_min):\n",
    "    return apriori_impl(data, num_key, max_id_key, pattern_min, done_index=set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.iloc[df.index.difference(['age','capital-gain'])].describe())\n",
    "\n",
    "num_key = 2 # Nombre de clef dans un pattron\n",
    "pattern_min = 1000 # Nombre minimal pour être un patron\n",
    "max_id_key = 2 # Quantité de chaque clef à considérer\n",
    "\n",
    "# pattern = apriori(df, num_key, max_id_key, pattern_min)\n",
    "\n",
    "# print(pattern) trop gros pour imprimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('float_format', '{:.1f}'.format)\n",
    "\n",
    "def print_pattern(pattern):\n",
    "    ks = pattern.keys()\n",
    "    for k in range(len(ks)):\n",
    "        key = list(pattern.keys())[k]\n",
    "        if type(pattern[key]) != dict:\n",
    "            display(pattern[key])\n",
    "        else:\n",
    "            print_pattern(pattern[key])\n",
    "\n",
    "#print_pattern(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspects éthiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age   fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
      "income                                                              \n",
      "<=50K  37.4 194217.3              9.6        5010.3         264.9   \n",
      ">50K   44.8 192979.2             11.6        7941.8         392.4   \n",
      "\n",
      "        hours-per-week  \n",
      "income                  \n",
      "<=50K             42.2  \n",
      ">50K              48.9  \n",
      "Ratio >50K Homme/Femme == 5.6066\n",
      "Ratio <=50K Homme/Femme == 1.5761\n"
     ]
    }
   ],
   "source": [
    "male = df[df['gender'] == 'Male']\n",
    "female = df[df['gender'] == 'Female']\n",
    "\n",
    "rich_male = male[male['income'] == '>50K'].shape[0]\n",
    "rich_female = female[female['income'] == '>50K'].shape[0]\n",
    "poor_male = male[male['income'] == '<=50K'].shape[0]\n",
    "poor_female = female[female['income'] == '<=50K'].shape[0]\n",
    "\n",
    "print(df.groupby('income').mean())\n",
    "print(\"Ratio >50K Homme/Femme == %.4f\" % (rich_male / rich_female))\n",
    "print(\"Ratio <=50K Homme/Femme == %.4f\" % (poor_male / poor_female))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "Ces chiffres montrent qu'il y a plus de 5 fois plus d'homme que de femme avec un salaire en haut de 50 000 tandis qu'il y a moins de 2 fois plus d'homme avec un salaire en dessous de 50 000.\n",
    "\n",
    "Il y a deux possibilités: peut-être que ces données sont erronées (ou incomplètes) ou qu'il y a vraiment une différence entre homme et femme. Si les données ne sont pas erronées ni incomplètes alors ce jeu de données pourrait dans certains contextes être utilisé pour faire des prédictions. Il y a quand même une nuance à faire: si on utilise ce jeu de données pour prendre des décisions alors il faut se demander si cette différence est pertinente. Sans compter que le jeu de données pourrait être le reflet de plusieurs autres phénomènes sociaux plus ou moins pertinents. C'est à dire que toutes décisions prisent automatiquement à l'aide d'un algorithme pourraient être basées en partie sur ces problèmes éthiques plutôt que sur des éléments rationnels et/ou sur des valeurs communément acceptées.\n",
    "\n",
    "En d'autres termes, des données représentatives peuvent dans certains contextes être utilisées pour faire des prédictions. Le problème se corse lorsqu'on veut aussi prendre une décision. Par exemple, si on veut prendre une décision sur les salaires dans une entreprise il faut se demander si ces caractérisques doivent réellement être considérées. En générale on voudrait probablement considérer l'éducation pour déterminer un salaire mais pas le sexe. Il faut donc prendre soin de sélectionner des caractérisques pertinentes. Dans le cas contraire et comme nous avons vue dans le cours, il peut exister un indice de corrélation non null sur des données qui ne sont pas du tout en lien avec la décision qu'on s'aprète à prendre.\n",
    "\n",
    "Si ces données reste pertinentes dans certains cas c'est parce qu'il n'est pas toujours facile de faire la distinction entre une relation de causation et une corrélation due au hasard. Il est à la fois possible de trouver des corrélations duent au hasard, des corrélations duent à des problèmes éthiques et des corrélations duent à une relation de causation pertinente. Il y a quand même une relation de causation si la corrélations est due à des problèmes éthiques mais la corrélation n'est pas nécessairement pertinente pour la question abordée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
